{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enviroment prepare (imports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import  DataLoader,SubsetRandomSampler,ConcatDataset,Subset\n",
    "from sklearn.model_selection import KFold\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA PREPARE\n",
    "\n",
    "###### Here we'll use a affectnet net as training and final test test validation to our CNN model, where we're going to test 3 principal models: VGG, RESNET AlexNet. As validation, the FER-2013 dataset will be splited and cross validate with the training data to have a more robust trainig.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORT DATA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformation functions and hyper variables\n",
    "\n",
    "###### Here we opted to use a 64x64px image proportion, because face images usually have a smaller size in pictures when we extract."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "classes = ('angry', 'fear', 'happy', 'neutral', 'sad', 'surprise','disgust')\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    # transforms.Resize((64,64)),\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.ImageFolder('./fer_ckplus_dataset', transform=train_transform)\n",
    "train_loaded = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "validation_dataset = datasets.ImageFolder('./color_dataset_2/train', transform=train_transform)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation \n",
    "\n",
    "###### We'll use the cross validation with a diferent dataset, to improve the cnn knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=10\n",
    "splits=KFold(n_splits=k,shuffle=True,random_state=42)\n",
    "foldperf={}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Models Architecture"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AlexNet model to 64x64px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FacialExpressionAlexNet(nn.Module):\n",
    "    def __init__(self, num_classes=7):\n",
    "        super(FacialExpressionAlexNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=2),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "\n",
    "            nn.Conv2d(96, 256, kernel_size=5, padding=2),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "\n",
    "            nn.Conv2d(256, 384, kernel_size=3, padding=1),\n",
    "\n",
    "            nn.Conv2d(384, 384, kernel_size=3, padding=1),\n",
    "\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        )\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "\n",
    "            nn.Linear(4096, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG19(nn.Module):\n",
    "    def __init__(self, num_classes=7):\n",
    "        super(VGG19, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((7, 7))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512 * 7 * 7, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGG19()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runing on: cuda\n"
     ]
    }
   ],
   "source": [
    "# Define your execution device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Runing on: \"+ (\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr=learning_rate,  weight_decay = 0.001)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveModel():\n",
    "    torch.save(model.state_dict(), \"apurated_model.pth\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Validation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model,device,dataloader):\n",
    "    train_loss,train_correct=0.0,0\n",
    "    model.train()\n",
    "    for images, labels in dataloader:\n",
    "\n",
    "        images,labels = images.to(device),labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(images)\n",
    "        loss = loss_fn(output,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * images.size(0)\n",
    "        scores, predictions = torch.max(output.data, 1)\n",
    "        train_correct += (predictions == labels).sum().item()\n",
    "\n",
    "    return train_loss,train_correct\n",
    "  \n",
    "def valid_epoch(model,device,dataloader):\n",
    "    valid_loss, val_correct = 0.0, 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "\n",
    "            images,labels = images.to(device),labels.to(device)\n",
    "            output = model(images)\n",
    "            loss=loss_fn(output,labels)\n",
    "            valid_loss+=loss.item()*images.size(0)\n",
    "            scores, predictions = torch.max(output.data,1)\n",
    "            val_correct+=(predictions == labels).sum().item()\n",
    "\n",
    "    return valid_loss,val_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(num_epochs):\n",
    "    history = {'train_loss': [], 'test_loss': [],'train_acc':[],'test_acc':[]}\n",
    "    best_accuracy = 0.0\n",
    "\n",
    "    model.to(device)\n",
    "    \n",
    "    for fold, (train_idx,val_idx) in enumerate(splits.split(np.arange(len(validation_dataset)))):\n",
    "\n",
    "        print('Fold {}'.format(fold + 1))\n",
    "\n",
    "        test_sampler = SubsetRandomSampler(val_idx)\n",
    "        test_loader = DataLoader(validation_dataset, batch_size=batch_size, sampler=test_sampler)\n",
    "        \n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            train_loss, train_correct=train_epoch(model,device,train_loaded)\n",
    "            test_loss, test_correct=valid_epoch(model,device,test_loader)\n",
    "\n",
    "            train_loss = train_loss / len(train_loaded.sampler)\n",
    "            train_acc = train_correct / len(train_loaded.sampler) * 100\n",
    "\n",
    "            test_loss = test_loss / len(test_loader.sampler)\n",
    "            test_acc = test_correct / len(test_loader.sampler) * 100\n",
    "\n",
    "            print(\"Epoch:{}/{} AVG Training Loss:{:.3f} AVG Test Loss:{:.3f} AVG Training Acc {:.2f} % AVG Test Acc {:.2f} %\".format(epoch + 1,\n",
    "                                                                                                                    num_epochs,\n",
    "                                                                                                                    train_loss,\n",
    "                                                                                                                    test_loss,\n",
    "                                                                                                                    train_acc,\n",
    "                                                                                                                    test_acc))\n",
    "            if train_acc > best_accuracy:\n",
    "                saveModel()\n",
    "                best_accuracy = train_acc\n",
    "                print(\"Best Accuracy:{} %\".format(best_accuracy))\n",
    "\n",
    "            history['train_loss'].append(train_loss)\n",
    "            history['test_loss'].append(test_loss)\n",
    "            history['train_acc'].append(train_acc)\n",
    "            history['test_acc'].append(test_acc)   \n",
    "\n",
    "    df_history = pd.DataFrame(data=history)\n",
    "    df_history.to_csv(\"historic.csv\", encoding='utf-8', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Epoch:1/10 AVG Training Loss:3.786 AVG Test Loss:1.932 AVG Training Acc 23.88 % AVG Test Acc 18.56 %\n",
      "Best Accuracy:23.884610683290553 %\n",
      "Epoch:2/10 AVG Training Loss:2.450 AVG Test Loss:1.950 AVG Training Acc 26.98 % AVG Test Acc 18.56 %\n",
      "Best Accuracy:26.980198019801982 %\n",
      "Epoch:3/10 AVG Training Loss:22313.729 AVG Test Loss:1.971 AVG Training Acc 27.02 % AVG Test Acc 18.56 %\n",
      "Best Accuracy:27.019924214643687 %\n",
      "Epoch:4/10 AVG Training Loss:13127.991 AVG Test Loss:1.986 AVG Training Acc 27.51 % AVG Test Acc 18.56 %\n",
      "Best Accuracy:27.511917858452513 %\n",
      "Epoch:5/10 AVG Training Loss:20394.231 AVG Test Loss:1.996 AVG Training Acc 27.27 % AVG Test Acc 18.56 %\n",
      "Epoch:6/10 AVG Training Loss:4136.192 AVG Test Loss:2.004 AVG Training Acc 27.45 % AVG Test Acc 18.56 %\n",
      "Epoch:7/10 AVG Training Loss:1105.620 AVG Test Loss:2.010 AVG Training Acc 27.30 % AVG Test Acc 18.56 %\n",
      "Epoch:8/10 AVG Training Loss:1003.187 AVG Test Loss:2.009 AVG Training Acc 27.35 % AVG Test Acc 18.56 %\n",
      "Epoch:9/10 AVG Training Loss:316.531 AVG Test Loss:2.012 AVG Training Acc 27.24 % AVG Test Acc 18.56 %\n",
      "Epoch:10/10 AVG Training Loss:350.535 AVG Test Loss:2.014 AVG Training Acc 27.46 % AVG Test Acc 18.56 %\n",
      "Fold 2\n",
      "Epoch:1/10 AVG Training Loss:585.059 AVG Test Loss:2.007 AVG Training Acc 27.26 % AVG Test Acc 19.15 %\n",
      "Epoch:2/10 AVG Training Loss:511.532 AVG Test Loss:2.006 AVG Training Acc 27.42 % AVG Test Acc 19.15 %\n",
      "Epoch:3/10 AVG Training Loss:1079.827 AVG Test Loss:2.004 AVG Training Acc 27.40 % AVG Test Acc 19.15 %\n",
      "Epoch:4/10 AVG Training Loss:379.341 AVG Test Loss:2.002 AVG Training Acc 27.49 % AVG Test Acc 19.15 %\n",
      "Epoch:5/10 AVG Training Loss:120955.398 AVG Test Loss:2.001 AVG Training Acc 27.27 % AVG Test Acc 19.15 %\n",
      "Epoch:6/10 AVG Training Loss:4613.234 AVG Test Loss:2.004 AVG Training Acc 27.54 % AVG Test Acc 19.15 %\n",
      "Best Accuracy:27.53942060872754 %\n",
      "Epoch:7/10 AVG Training Loss:8660.604 AVG Test Loss:2.003 AVG Training Acc 27.23 % AVG Test Acc 19.15 %\n",
      "Epoch:8/10 AVG Training Loss:14765.538 AVG Test Loss:2.004 AVG Training Acc 27.53 % AVG Test Acc 19.15 %\n",
      "Epoch:9/10 AVG Training Loss:1444.186 AVG Test Loss:2.004 AVG Training Acc 27.59 % AVG Test Acc 19.15 %\n",
      "Best Accuracy:27.59442610927759 %\n",
      "Epoch:10/10 AVG Training Loss:9892.325 AVG Test Loss:2.002 AVG Training Acc 27.48 % AVG Test Acc 19.15 %\n",
      "Fold 3\n",
      "Epoch:1/10 AVG Training Loss:1173.374 AVG Test Loss:1.985 AVG Training Acc 27.49 % AVG Test Acc 20.57 %\n",
      "Epoch:2/10 AVG Training Loss:1805.142 AVG Test Loss:1.985 AVG Training Acc 27.53 % AVG Test Acc 20.57 %\n",
      "Epoch:3/10 AVG Training Loss:113.072 AVG Test Loss:1.986 AVG Training Acc 27.55 % AVG Test Acc 20.57 %\n",
      "Epoch:4/10 AVG Training Loss:181.876 AVG Test Loss:1.987 AVG Training Acc 27.57 % AVG Test Acc 20.57 %\n",
      "Epoch:5/10 AVG Training Loss:229.416 AVG Test Loss:1.986 AVG Training Acc 27.56 % AVG Test Acc 20.57 %\n",
      "Epoch:6/10 AVG Training Loss:5264.060 AVG Test Loss:1.984 AVG Training Acc 27.23 % AVG Test Acc 20.57 %\n",
      "Epoch:7/10 AVG Training Loss:13265.711 AVG Test Loss:1.986 AVG Training Acc 27.43 % AVG Test Acc 20.57 %\n",
      "Epoch:8/10 AVG Training Loss:45404.829 AVG Test Loss:1.987 AVG Training Acc 27.49 % AVG Test Acc 20.57 %\n",
      "Epoch:9/10 AVG Training Loss:15201.058 AVG Test Loss:1.988 AVG Training Acc 27.61 % AVG Test Acc 20.57 %\n",
      "Best Accuracy:27.61276127612761 %\n",
      "Epoch:10/10 AVG Training Loss:9636.609 AVG Test Loss:1.986 AVG Training Acc 27.54 % AVG Test Acc 20.57 %\n",
      "Fold 4\n",
      "Epoch:1/10 AVG Training Loss:5417.658 AVG Test Loss:1.979 AVG Training Acc 27.51 % AVG Test Acc 19.58 %\n",
      "Epoch:2/10 AVG Training Loss:403.253 AVG Test Loss:1.981 AVG Training Acc 27.61 % AVG Test Acc 19.58 %\n",
      "Epoch:3/10 AVG Training Loss:1243.618 AVG Test Loss:1.981 AVG Training Acc 27.47 % AVG Test Acc 19.58 %\n",
      "Epoch:4/10 AVG Training Loss:1383.187 AVG Test Loss:1.981 AVG Training Acc 27.52 % AVG Test Acc 19.58 %\n",
      "Epoch:5/10 AVG Training Loss:516.361 AVG Test Loss:1.980 AVG Training Acc 27.62 % AVG Test Acc 19.58 %\n",
      "Best Accuracy:27.618872998410954 %\n",
      "Epoch:6/10 AVG Training Loss:874.025 AVG Test Loss:1.981 AVG Training Acc 27.66 % AVG Test Acc 19.58 %\n",
      "Best Accuracy:27.65859919325266 %\n",
      "Epoch:7/10 AVG Training Loss:2383.047 AVG Test Loss:1.980 AVG Training Acc 27.63 % AVG Test Acc 19.58 %\n",
      "Epoch:8/10 AVG Training Loss:1204.094 AVG Test Loss:1.980 AVG Training Acc 27.61 % AVG Test Acc 19.58 %\n",
      "Epoch:9/10 AVG Training Loss:1951.376 AVG Test Loss:1.981 AVG Training Acc 27.63 % AVG Test Acc 19.58 %\n",
      "Epoch:10/10 AVG Training Loss:365.594 AVG Test Loss:1.981 AVG Training Acc 27.63 % AVG Test Acc 19.58 %\n",
      "Fold 5\n",
      "Epoch:1/10 AVG Training Loss:247.609 AVG Test Loss:1.999 AVG Training Acc 27.63 % AVG Test Acc 19.62 %\n",
      "Epoch:2/10 AVG Training Loss:175.989 AVG Test Loss:1.999 AVG Training Acc 27.62 % AVG Test Acc 19.62 %\n",
      "Epoch:3/10 AVG Training Loss:29316.692 AVG Test Loss:1.999 AVG Training Acc 27.60 % AVG Test Acc 19.62 %\n",
      "Epoch:4/10 AVG Training Loss:2004.541 AVG Test Loss:1.999 AVG Training Acc 27.63 % AVG Test Acc 19.62 %\n",
      "Epoch:5/10 AVG Training Loss:850.158 AVG Test Loss:1.999 AVG Training Acc 27.63 % AVG Test Acc 19.62 %\n",
      "Epoch:6/10 AVG Training Loss:537.759 AVG Test Loss:2.001 AVG Training Acc 27.64 % AVG Test Acc 19.62 %\n",
      "Epoch:7/10 AVG Training Loss:761.399 AVG Test Loss:2.000 AVG Training Acc 27.65 % AVG Test Acc 19.62 %\n",
      "Epoch:8/10 AVG Training Loss:1213.938 AVG Test Loss:2.000 AVG Training Acc 27.65 % AVG Test Acc 19.62 %\n",
      "Epoch:9/10 AVG Training Loss:1949.610 AVG Test Loss:2.000 AVG Training Acc 27.64 % AVG Test Acc 19.62 %\n",
      "Epoch:10/10 AVG Training Loss:327.466 AVG Test Loss:1.998 AVG Training Acc 27.64 % AVG Test Acc 19.62 %\n",
      "Fold 6\n",
      "Epoch:1/10 AVG Training Loss:877.681 AVG Test Loss:1.984 AVG Training Acc 27.65 % AVG Test Acc 19.19 %\n",
      "Epoch:2/10 AVG Training Loss:2263.866 AVG Test Loss:1.984 AVG Training Acc 27.63 % AVG Test Acc 19.19 %\n",
      "Epoch:3/10 AVG Training Loss:3375.292 AVG Test Loss:1.984 AVG Training Acc 27.65 % AVG Test Acc 19.19 %\n",
      "Epoch:4/10 AVG Training Loss:4696.878 AVG Test Loss:1.984 AVG Training Acc 27.66 % AVG Test Acc 19.19 %\n",
      "Epoch:5/10 AVG Training Loss:679.766 AVG Test Loss:1.984 AVG Training Acc 27.64 % AVG Test Acc 19.19 %\n",
      "Epoch:6/10 AVG Training Loss:257.266 AVG Test Loss:1.983 AVG Training Acc 27.63 % AVG Test Acc 19.19 %\n",
      "Epoch:7/10 AVG Training Loss:4620.414 AVG Test Loss:1.984 AVG Training Acc 27.63 % AVG Test Acc 19.19 %\n",
      "Epoch:8/10 AVG Training Loss:305.232 AVG Test Loss:1.984 AVG Training Acc 27.63 % AVG Test Acc 19.19 %\n",
      "Epoch:9/10 AVG Training Loss:525.695 AVG Test Loss:1.982 AVG Training Acc 27.64 % AVG Test Acc 19.19 %\n"
     ]
    }
   ],
   "source": [
    "train(10)\n",
    "print('Finished Training')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
